# Adversarial Robustness Against the Union of Multiple Threat Models

Anonymised Repository for the Submission: Adversarial Robustness Against the Union of Multiple Threat Models

## What does this repository contain?
Code for training and evaluating all the experiments that support the aforementioned paper are provided in this repository. 
The instructions for reproducing the results can be found in the folder `MNIST` and `CIFAR10` respectively. We also provide trained models for each of the adversarial training methods in the sub-folder `Selected` for the two datasets. You can also find the exact parameters used to train each of the models in the same folder.

## Dependencies
The repository is written using `python 3.7`. To install dependencies run the command:

`pip install -r requirements.txt`
